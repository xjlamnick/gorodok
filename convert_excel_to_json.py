import pandas as pd
import json
import os
import sys

EXCEL_FILE = "sales.xlsx"
JSON_FILE = "sales-data.json"

gradients = [
    'linear-gradient(135deg, #FFD700 0%, #FFA500 100%)',
    'linear-gradient(135deg, #667eea 0%, #764ba2 100%)',
    'linear-gradient(135deg, #f093fb 0%, #f5576c 100%)',
    'linear-gradient(135deg, #4facfe 0%, #00f2fe 100%)',
    'linear-gradient(135deg, #43e97b 0%, #38f9d7 100%)',
    'linear-gradient(135deg, #fa709a 0%, #fee140 100%)',
    'linear-gradient(135deg, #30cfd0 0%, #330867 100%)',
    'linear-gradient(135deg, #a8edea 0%, #fed6e3 100%)',
    'linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%)'
]

PERCENT_COLS = ['% –î–æ–ª—è ACC', '–î–æ–ª—è –ü–æ—Å–ª—É–≥', '–ö–æ–Ω–≤–µ—Ä—Å—ñ—è –ü–ö', '–ö–æ–Ω–≤–µ—Ä—Å—ñ—è –ü–ö Offline', '–î–æ–ª—è –£–î–°']
COUNT_COLS = ['–®—Ç.', '–ß–µ–∫–∏', '–ü–ß']
MONEY_COLS = ['–¢–û', 'ASP', '–°—Ä. –ß–µ–∫', 'ACC', '–ü–æ—Å–ª—É–≥–∏ –≥—Ä–Ω', '–£–î–°']

def normalize_number(val):
    if pd.isna(val):
        return 0.0
    if isinstance(val, str):
        val = val.replace('%', '').replace(',', '.').strip()
    try:
        return float(val)
    except:
        return 0.0


def main():
    if not os.path.exists(EXCEL_FILE):
        print(f"‚ùå –§–∞–π–ª {EXCEL_FILE} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        sys.exit(1)

    df = pd.read_excel(EXCEL_FILE, header=2, engine="openpyxl")

    required_columns = ["–ü–ö", "–ü–æ—Å–∞–¥–∞"]
    for col in required_columns:
        if col not in df.columns:
            print("‚ùå –ù–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏:", col)
            print("üëâ –ó–Ω–∞–π–¥–µ–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏:", list(df.columns))
            sys.exit(1)

    metric_columns = df.columns[2:]

    sales_data = []

    # ======================
    # –ü–†–û–î–ê–í–¶–Ü
    # ======================
    for idx, row in df.iterrows():
        name = str(row["–ü–ö"]).strip()
        if not name or name == "nan":
            continue

        parts = name.split()
        initials = "".join(p[0] for p in parts[:2]).upper()

        metrics = {}

        for col in metric_columns:
            num = normalize_number(row[col])

            if col in PERCENT_COLS:
                value = round(num, 2)
                unit = "%"
            elif col in COUNT_COLS:
                value = int(num)
                unit = "—à—Ç"
            elif col in MONEY_COLS:
                value = round(num, 2)
                unit = "–≥—Ä–Ω"
            else:
                value = round(num, 2)
                unit = ""

            metrics[col] = {
                "value": value,
                "label": col,
                "unit": unit
            }

        sales_data.append({
            "id": len(sales_data) + 1,
            "name": name,
            "position": str(row["–ü–æ—Å–∞–¥–∞"]) if pd.notna(row["–ü–æ—Å–∞–¥–∞"]) else "–ø—Ä–æ–¥–∞–≤–µ—Ü-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç",
            "initials": initials,
            "gradient": gradients[(len(sales_data)) % len(gradients)],
            "metrics": metrics
        })

    # ======================
    # –ú–ê–ì–ê–ó–ò–ù (–§–û–†–ú–£–õ–ò)
    # ======================
    total_metrics = {}

    total_TO = df["–¢–û"].apply(normalize_number).sum()
    total_units = df["–®—Ç."].apply(normalize_number).sum()
    total_checks = df["–ß–µ–∫–∏"].apply(normalize_number).sum()
    total_ACC = df["ACC"].apply(normalize_number).sum()
    total_services = df["–ü–æ—Å–ª—É–≥–∏ –≥—Ä–Ω"].apply(normalize_number).sum()
    total_UDS = df["–£–î–°"].apply(normalize_number).sum()
    total_PCH = df["–ü–ß"].apply(normalize_number).sum()

    avg_conv = df["–ö–æ–Ω–≤–µ—Ä—Å—ñ—è –ü–ö"].apply(normalize_number).mean()
    avg_conv_off = df["–ö–æ–Ω–≤–µ—Ä—Å—ñ—è –ü–ö Offline"].apply(normalize_number).mean()

    def safe_div(a, b):
        return round(a / b, 2) if b != 0 else 0

    computed = {
        "–¢–û": (round(total_TO, 2), "–≥—Ä–Ω"),
        "–®—Ç.": (int(total_units), "—à—Ç"),
        "–ß–µ–∫–∏": (int(total_checks), "—à—Ç"),
        "ASP": (safe_div(total_TO, total_units), "–≥—Ä–Ω"),
        "–°—Ä. –ß–µ–∫": (safe_div(total_TO, total_checks), "–≥—Ä–Ω"),
        "–ö–ü–ß": (safe_div(total_units, total_checks), ""),
        "ACC": (round(total_ACC, 2), "–≥—Ä–Ω"),
        "% –î–æ–ª—è ACC": (safe_div(total_ACC * 100, total_TO), "%"),
        "–ü–æ—Å–ª—É–≥–∏ –≥—Ä–Ω": (round(total_services, 2), "–≥—Ä–Ω"),
        "–î–æ–ª—è –ü–æ—Å–ª—É–≥": (safe_div(total_services * 100, total_TO), "%"),
        "–ü–ß": (int(total_PCH), "—à—Ç"),
        "–ö–æ–Ω–≤–µ—Ä—Å—ñ—è –ü–ö": (round(avg_conv, 2), "%"),
        "–ö–æ–Ω–≤–µ—Ä—Å—ñ—è –ü–ö Offline": (round(avg_conv_off, 2), "%"),
        "–£–î–°": (round(total_UDS, 2), "–≥—Ä–Ω"),
        "–î–æ–ª—è –£–î–°": (safe_div(total_UDS * 100, total_TO), "%")
    }

    for key, (value, unit) in computed.items():
        total_metrics[key] = {
            "value": value,
            "label": key,
            "unit": unit
        }

    sales_data.insert(0, {
        "id": 0,
        "name": "–ó–∞–≥–∞–ª—å–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ –º–∞–≥–∞–∑–∏–Ω—É",
        "position": "–í—Å—ñ –ø—Ä–æ–¥–∞–≤—Ü—ñ",
        "initials": "–ú–ê–ì",
        "gradient": gradients[0],
        "metrics": total_metrics
    })

    with open(JSON_FILE, "w", encoding="utf-8") as f:
        json.dump(sales_data, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ {JSON_FILE}")
    print(f"üë• –ó–∞–ø–∏—Å—ñ–≤: {len(sales_data)}")


if __name__ == "__main__":
    main()
